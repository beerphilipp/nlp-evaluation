{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ecbd2758-dfef-4747-8ccd-364d5cc55d09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "INPUT_DATA_DIR = \"../data/input\"\n",
    "OUTPUT_DATA_DIR = \"../data/output\"\n",
    "\n",
    "INTERMEDIARY_CSV = os.path.join(OUTPUT_DATA_DIR, current_date + \"_merged_preprocessed.csv\")\n",
    "\n",
    "NRC_DIR = os.path.join(INPUT_DATA_DIR, \"nrc\")\n",
    "NRC_POSITIVE = os.path.join(NRC_DIR, os.path.join(\"OneFilePerEmotion\", \"positive-NRC-Emotion-Lexicon.txt\"))\n",
    "NRC_NEGATIVE = os.path.join(NRC_DIR, os.path.join(\"OneFilePerEmotion\", \"negative-NRC-Emotion-Lexicon.txt\"))\n",
    "\n",
    "NRC_ALL_POSITIVE = [NRC_POSITIVE]\n",
    "NRC_ALL_NEGATIVE = [NRC_NEGATIVE]\n",
    "\n",
    "\n",
    "OUTPUT_CSV_FILE = os.path.join(OUTPUT_DATA_DIR, current_date + \"_predicted_rating.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29346cc9",
   "metadata": {},
   "source": [
    "# Read the NRC emotion lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "207f8709",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = []\n",
    "\n",
    "for pos in NRC_ALL_POSITIVE:\n",
    "    with open(pos, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            split = line.split()\n",
    "            if int(split[1]) == 1:\n",
    "                positive.append(split[0])\n",
    "\n",
    "negative = []\n",
    "for neg in NRC_ALL_NEGATIVE:\n",
    "    with open(neg, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            split = line.split()\n",
    "            if int(split[1]) == 1:\n",
    "                negative.append(split[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4e1b324",
   "metadata": {},
   "source": [
    "# Calculate the predicted rating for each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "63696f13-e8ee-4ea0-8ef7-06a9a04cd7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(INTERMEDIARY_CSV)\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: ast.literal_eval(x))\n",
    "def calculate_score(row):\n",
    "    trimmed_array = row['cleaned_text']\n",
    "    score = 0\n",
    "    count = 0\n",
    "    for word in trimmed_array:\n",
    "        if word in positive and word in negative:\n",
    "            continue\n",
    "        elif word in positive:\n",
    "            count += 1\n",
    "            score += 5\n",
    "        elif word in negative:\n",
    "            count += 1\n",
    "            score -= 1\n",
    "\n",
    "    if count == 0:\n",
    "        return -1\n",
    "    predicted = score/count\n",
    "    if (predicted < 1):\n",
    "        return 1\n",
    "    return score/count\n",
    "\n",
    "def score_to_category(rating):\n",
    "    if rating < 2.5:\n",
    "        return 'bad'\n",
    "    else:\n",
    "        return 'good'\n",
    "\n",
    "df['predicted_rating'] = df.apply(calculate_score, axis = 1)\n",
    "df = df[df['predicted_rating'] != -1]\n",
    "\n",
    "df['category'] = df['rating'].apply(score_to_category)\n",
    "\n",
    "df['predicted_category'] = df['predicted_rating'].apply(score_to_category)\n",
    "\n",
    "def rating_round(rating):\n",
    "    return int(round(rating))\n",
    "\n",
    "df['predicted_rating_discrete'] = df['predicted_rating'].apply(rating_round)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7aa398ba",
   "metadata": {},
   "source": [
    "# Write the results to `data/output/result.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d657b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(OUTPUT_CSV_FILE, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
